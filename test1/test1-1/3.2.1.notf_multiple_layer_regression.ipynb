{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "rand_std = 0.030\n",
    "learning_rate = 0.001\n",
    "epoch_count = 100\n",
    "report_period = 10\n",
    "random_fix = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "data = iris_dataset.data\n",
    "target = iris_dataset.target\n",
    "target_names = iris_dataset.target_names\n",
    "\n",
    "#print(\"dimension: data{}, target{}, target_names{}\".\n",
    "#    format(data.shape, target.shape, target_names.shape))\n",
    "#print(target_names)\n",
    "#print(data[:5])\n",
    "#print(target[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_fix: np.random.seed(1234)\n",
    "\n",
    "data_count = len(data)\n",
    "train_count = int(data_count * train_ratio)\n",
    "test_count = data_count - train_count\n",
    "    \n",
    "indices = np.arange(data_count)\n",
    "np.random.shuffle(indices)\n",
    "    \n",
    "train_data = data[indices[0:train_count]]\n",
    "train_target = target[indices[0:train_count]]\n",
    "    \n",
    "test_data = data[indices[train_count:data_count]]\n",
    "test_target = target[indices[train_count:data_count]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, output_dim = 3, 1\n",
    "\n",
    "def get_test_data():\n",
    "    test_X = test_data[:, 0:3]\n",
    "    test_Y = test_data[:, 3:4]\n",
    "\n",
    "    return test_X, test_Y\n",
    "\n",
    "def get_train_data(batch_size, nth):\n",
    "    global indices\n",
    "    \n",
    "    if nth == 0:\n",
    "        indices = np.arange(train_count)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    from_idx = nth * batch_size\n",
    "    to_idx = (nth + 1) * batch_size\n",
    "    \n",
    "    train_X = train_data[indices[from_idx:to_idx], 0:3]\n",
    "    train_Y = train_data[indices[from_idx:to_idx], 3:4]   \n",
    "    \n",
    "    return train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rand_normal(in_dim, out_dim):\n",
    "    init_64 = np.random.normal(0, rand_std, [in_dim, out_dim])\n",
    "    init = init_64.astype('float32')\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 10\n",
    "\n",
    "def init_parameter():\n",
    "    if random_fix: np.random.seed(9876)\n",
    "\n",
    "    global w_hid, b_hid, w_out, b_out\n",
    "    \n",
    "    w_hid = init_rand_normal(input_dim, hidden_dim)\n",
    "    b_hid = np.zeros([hidden_dim])\n",
    "\n",
    "    w_out = init_rand_normal(hidden_dim, output_dim)\n",
    "    b_out = np.zeros([output_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)     # np.max(x, 0)\n",
    "\n",
    "def relu_derv(y):\n",
    "    return np.sign(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_forward(x):\n",
    "    global w_hid, b_hid, w_out, b_out\n",
    "    global hidden\n",
    "    \n",
    "    hidden = relu(np.matmul(x, w_hid) + b_hid)\n",
    "    output = np.matmul(hidden, w_out) + b_out\n",
    "    \n",
    "    return output\n",
    "\n",
    "def proc_backward(x, grad):\n",
    "    global w_hid, b_hid, w_out, b_out\n",
    "    global hidden\n",
    "    \n",
    "    w_out_derv = hidden.transpose()\n",
    "    w_out_grad = np.matmul(w_out_derv, grad)\n",
    "    \n",
    "    b_out_grad = np.sum(grad, axis=0)\n",
    "    \n",
    "    hidden_derv = w_out.transpose()\n",
    "    hidden_grad = np.matmul(grad, hidden_derv)\n",
    "    \n",
    "    hidden_affine_derv = relu_derv(hidden)\n",
    "    hidden_affine_grad = hidden_affine_derv * hidden_grad\n",
    "    \n",
    "    w_hid_derv = x.transpose()\n",
    "    w_hid_grad = np.matmul(w_hid_derv, hidden_affine_grad)\n",
    "    \n",
    "    b_hid_grad = np.sum(hidden_affine_grad, axis=0)\n",
    "    \n",
    "    w_hid = w_hid - learning_rate * w_hid_grad\n",
    "    b_hid = b_hid - learning_rate * b_hid_grad\n",
    "    \n",
    "    w_out = w_out - learning_rate * w_out_grad\n",
    "    b_out = b_out - learning_rate * b_out_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(output, y):\n",
    "    return 1 - np.mean(np.abs(output-y) / y)\n",
    "\n",
    "def test(x, y):\n",
    "    output = proc_forward(x)\n",
    "    return eval_accuracy(output, y)\n",
    "\n",
    "def train_step(x, y):\n",
    "    output = proc_forward(x)\n",
    "    diff = output - y\n",
    "    power = np.power(diff, 2)\n",
    "    loss = np.mean(power)\n",
    "    \n",
    "    loss_grad = 1.0\n",
    "    \n",
    "    power_derv = np.ones_like(y) / np.prod(y.shape)\n",
    "    power_grad = power_derv * loss_grad\n",
    "    \n",
    "    diff_derv = 2 * diff\n",
    "    diff_grad = diff_derv * power_grad\n",
    "    \n",
    "    output_derv = 1\n",
    "    output_grad = output_derv * diff_grad\n",
    "    \n",
    "    proc_backward(x, output_grad)\n",
    "    \n",
    "    return loss, eval_accuracy(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(batch_size=0):\n",
    "    if batch_size == 0: batch_size = train_count\n",
    "    batch_count = int(train_count / batch_size)\n",
    "    test_X, test_Y = get_test_data()\n",
    "        \n",
    "    init_parameter()\n",
    "    \n",
    "    if random_fix: np.random.seed(1945)\n",
    "        \n",
    "    for epoch in range(epoch_count):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        for n in range(batch_count):\n",
    "            train_X, train_Y = get_train_data(batch_size, n)\n",
    "            cost, acc = train_step(train_X, train_Y)\n",
    "            costs.append(cost)\n",
    "            accs.append(acc)\n",
    "            \n",
    "        if (epoch+1) % report_period == 0:\n",
    "            acc = test(test_X, test_Y)\n",
    "            print(\"Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f}\". \\\n",
    "                  format(epoch+1, np.mean(costs), np.mean(accs), acc))\n",
    "            \n",
    "    final_acc = test(test_X, test_Y)\n",
    "    print(\"\\nFinal Test: final accuracy = {:5.3f}\".format(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=0.548, accuracy=0.070/-0.261\n",
      "Epoch 20: cost=0.265, accuracy=-0.221/-0.648\n",
      "Epoch 30: cost=0.229, accuracy=-0.130/-0.556\n",
      "Epoch 40: cost=0.196, accuracy=-0.040/-0.436\n",
      "Epoch 50: cost=0.165, accuracy=0.074/-0.317\n",
      "Epoch 60: cost=0.137, accuracy=0.179/-0.184\n",
      "Epoch 70: cost=0.112, accuracy=0.277/-0.049\n",
      "Epoch 80: cost=0.092, accuracy=0.388/0.071\n",
      "Epoch 90: cost=0.077, accuracy=0.468/0.194\n",
      "Epoch 100: cost=0.066, accuracy=0.555/0.294\n",
      "\n",
      "Final Test: final accuracy = 0.294\n"
     ]
    }
   ],
   "source": [
    "train_and_test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=1.866, accuracy=0.065/0.088\n",
      "Epoch 20: cost=1.779, accuracy=0.130/0.170\n",
      "Epoch 30: cost=1.684, accuracy=0.201/0.259\n",
      "Epoch 40: cost=1.580, accuracy=0.265/0.283\n",
      "Epoch 50: cost=1.462, accuracy=0.335/0.310\n",
      "Epoch 60: cost=1.329, accuracy=0.359/0.294\n",
      "Epoch 70: cost=1.183, accuracy=0.341/0.237\n",
      "Epoch 80: cost=1.028, accuracy=0.305/0.158\n",
      "Epoch 90: cost=0.871, accuracy=0.249/0.066\n",
      "Epoch 100: cost=0.723, accuracy=0.181/-0.042\n",
      "\n",
      "Final Test: final accuracy = -0.042\n"
     ]
    }
   ],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=0.074, accuracy=0.521/0.291\n",
      "Epoch 20: cost=0.049, accuracy=0.783/0.668\n",
      "Epoch 30: cost=0.048, accuracy=0.795/0.704\n",
      "Epoch 40: cost=0.046, accuracy=0.797/0.712\n",
      "Epoch 50: cost=0.045, accuracy=0.802/0.692\n",
      "Epoch 60: cost=0.044, accuracy=0.808/0.692\n",
      "Epoch 70: cost=0.044, accuracy=0.799/0.702\n",
      "Epoch 80: cost=0.043, accuracy=0.809/0.673\n",
      "Epoch 90: cost=0.043, accuracy=0.804/0.707\n",
      "Epoch 100: cost=0.042, accuracy=0.799/0.702\n",
      "\n",
      "Final Test: final accuracy = 0.702\n"
     ]
    }
   ],
   "source": [
    "train_and_test(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
