{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "rand_std = 0.030\n",
    "learning_rate = 0.001\n",
    "epoch_count = 100\n",
    "report_period = 10\n",
    "random_fix = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "data = iris_dataset.data\n",
    "target = iris_dataset.target\n",
    "target_names = iris_dataset.target_names\n",
    "\n",
    "#print(\"dimension: data{}, target{}, target_names{}\".\n",
    "#    format(data.shape, target.shape, target_names.shape))\n",
    "#print(target_names)\n",
    "#print(data[:5])\n",
    "#print(target[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_fix: np.random.seed(1234)\n",
    "\n",
    "data_count = len(data)\n",
    "train_count = int(data_count * train_ratio)\n",
    "test_count = data_count - train_count\n",
    "    \n",
    "indices = np.arange(data_count)\n",
    "np.random.shuffle(indices)\n",
    "    \n",
    "train_data = data[indices[0:train_count]]\n",
    "train_target = target[indices[0:train_count]]\n",
    "    \n",
    "test_data = data[indices[train_count:data_count]]\n",
    "test_target = target[indices[train_count:data_count]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, output_dim = 4, 3\n",
    "\n",
    "def get_test_data():\n",
    "    test_X = test_data\n",
    "    test_Y = np.zeros([test_count, 3])\n",
    "    \n",
    "    for i in range(test_count):\n",
    "        test_Y[i, test_target[i]] = 1.0\n",
    "        \n",
    "    return test_X, test_Y\n",
    "\n",
    "def get_train_data(batch_size, nth):\n",
    "    global indices\n",
    "    \n",
    "    if nth == 0:\n",
    "        indices = np.arange(train_count)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    from_idx = nth * batch_size\n",
    "    to_idx = (nth + 1) * batch_size\n",
    "    \n",
    "    train_X = train_data[indices[from_idx:to_idx]]\n",
    "    train_Y = np.zeros([batch_size, 3])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        k = indices[from_idx+i]\n",
    "        train_Y[i, train_target[k]] = 1.0\n",
    "        \n",
    "    return train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rand_normal(in_dim, out_dim):\n",
    "    init_64 = np.random.normal(0, rand_std, [in_dim, out_dim])\n",
    "    init = init_64.astype('float32')\n",
    "\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_dim = 8\n",
    "hidden2_dim = 4\n",
    "hidden3_dim = 2\n",
    "\n",
    "def init_parameter():\n",
    "    if random_fix: np.random.seed(9876)\n",
    "\n",
    "    global w_hid1,b_hid1, w_hid2,b_hid2, w_hid3,b_hid3, w_out,b_out\n",
    "    \n",
    "    w_hid1 = init_rand_normal(input_dim, hidden1_dim)\n",
    "    b_hid1 = np.zeros([hidden1_dim])\n",
    "\n",
    "    w_hid2 = init_rand_normal(hidden1_dim, hidden2_dim)\n",
    "    b_hid2 = np.zeros([hidden2_dim])\n",
    "\n",
    "    w_hid3 = init_rand_normal(hidden2_dim, hidden3_dim)\n",
    "    b_hid3 = np.zeros([hidden3_dim])\n",
    "\n",
    "    w_out = init_rand_normal(hidden3_dim, output_dim)\n",
    "    b_out = np.zeros([output_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)     # np.max(x, 0)\n",
    "\n",
    "def relu_derv(y):\n",
    "    return np.sign(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_forward(x):\n",
    "    global w_hid1,b_hid1, w_hid2,b_hid2, w_hid3,b_hid3, w_out,b_out\n",
    "    global hidden1, hidden2, hidden3\n",
    "    \n",
    "    hidden1 = relu(np.matmul(x, w_hid1) + b_hid1)\n",
    "    hidden2 = relu(np.matmul(hidden1, w_hid2) + b_hid2)\n",
    "    hidden3 = relu(np.matmul(hidden2, w_hid3) + b_hid3)\n",
    "    \n",
    "    output = np.matmul(hidden3, w_out) + b_out\n",
    "    \n",
    "    return output\n",
    "\n",
    "def proc_backward(x, grad):\n",
    "    global w_hid1,b_hid1, w_hid2,b_hid2, w_hid3,b_hid3, w_out,b_out\n",
    "    global hidden1, hidden2, hidden3\n",
    "    \n",
    "    w_out_derv = hidden3.transpose()\n",
    "    w_out_grad = np.matmul(w_out_derv, grad)\n",
    "    \n",
    "    b_out_grad = np.sum(grad, axis=0)\n",
    "    \n",
    "    hidden3_derv = w_out.transpose()\n",
    "    hidden3_grad = np.matmul(grad, hidden3_derv)\n",
    "    \n",
    "    hidden3_affine_derv = relu_derv(hidden3)\n",
    "    hidden3_affine_grad = hidden3_affine_derv * hidden3_grad\n",
    "    \n",
    "    w_hid3_derv = hidden2.transpose()\n",
    "    w_hid3_grad = np.matmul(w_hid3_derv, hidden3_affine_grad)\n",
    "    \n",
    "    b_hid3_grad = np.sum(hidden3_affine_grad, axis=0)\n",
    "    \n",
    "    hidden2_derv = w_hid3.transpose()\n",
    "    hidden2_grad = np.matmul(hidden3_affine_grad, hidden2_derv)\n",
    "    \n",
    "    hidden2_affine_derv = relu_derv(hidden2)\n",
    "    hidden2_affine_grad = hidden2_affine_derv * hidden2_grad\n",
    "    \n",
    "    w_hid2_derv = hidden1.transpose()\n",
    "    w_hid2_grad = np.matmul(w_hid2_derv, hidden2_affine_grad)\n",
    "    \n",
    "    b_hid2_grad = np.sum(hidden2_affine_grad, axis=0)\n",
    "    \n",
    "    hidden1_derv = w_hid2.transpose()\n",
    "    hidden1_grad = np.matmul(hidden2_affine_grad, hidden1_derv)\n",
    "    \n",
    "    hidden1_affine_derv = relu_derv(hidden1)\n",
    "    hidden1_affine_grad = hidden1_affine_derv * hidden1_grad\n",
    "    \n",
    "    w_hid1_derv = x.transpose()\n",
    "    w_hid1_grad = np.matmul(w_hid1_derv, hidden1_affine_grad)\n",
    "    \n",
    "    b_hid1_grad = np.sum(hidden1_affine_grad, axis=0)\n",
    "    \n",
    "    w_hid3 = w_hid3 - learning_rate * w_hid3_grad\n",
    "    b_hid3 = b_hid3 - learning_rate * b_hid3_grad\n",
    "    \n",
    "    w_hid2 = w_hid2 - learning_rate * w_hid2_grad\n",
    "    b_hid2 = b_hid2 - learning_rate * b_hid2_grad\n",
    "    \n",
    "    w_hid1 = w_hid1 - learning_rate * w_hid1_grad\n",
    "    b_hid1 = b_hid1 - learning_rate * b_hid1_grad\n",
    "    \n",
    "    w_out = w_out - learning_rate * w_out_grad\n",
    "    b_out = b_out - learning_rate * b_out_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    max_elem = np.max(x, axis=1)\n",
    "    diff = (x.transpose() - max_elem).transpose()\n",
    "    exp = np.exp(diff)\n",
    "    sum_exp = np.sum(exp, axis=1)\n",
    "    probs = (exp.transpose() / sum_exp).transpose()\n",
    "    return probs\n",
    "\n",
    "def softmax_derv(x, y):\n",
    "    mb_size, nom_size = x.shape\n",
    "    derv = np.ndarray([mb_size, nom_size, nom_size])\n",
    "    for n in range(mb_size):\n",
    "        for i in range(nom_size):\n",
    "            for j in range(nom_size):\n",
    "                derv[n, i, j] = -y[n,i] * y[n,j]\n",
    "            derv[n, i, i] += y[n,i]\n",
    "    return derv\n",
    "\n",
    "def softmax_cross_entropy(p, q):\n",
    "    return -np.sum(p * np.log(q), axis=1)\n",
    "\n",
    "def softmax_cross_entropy_derv(p, q):\n",
    "    return -p / q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(output, y):\n",
    "    #probs = softmax(output)\n",
    "    #estimate = np.argmax(probs, axis=1)\n",
    "    estimate = np.argmax(output, axis=1)\n",
    "    answer = np.argmax(y, axis=1)\n",
    "    correct = np.equal(estimate, answer)\n",
    "    return np.mean(correct)\n",
    "\n",
    "def test(x, y):\n",
    "    output = proc_forward(x)\n",
    "    return eval_accuracy(output, y)\n",
    "\n",
    "def train_step(x, y):\n",
    "    output = proc_forward(x)\n",
    "    \n",
    "    probs = softmax(output)\n",
    "    entropy = softmax_cross_entropy(y, probs)\n",
    "    loss = np.mean(entropy)\n",
    "    \n",
    "    loss_grad = 1.0\n",
    "    \n",
    "    ent_grad = loss_grad / np.prod(entropy.shape)\n",
    "    \n",
    "    probs_derv = softmax_cross_entropy_derv(y, probs)\n",
    "    probs_grad = probs_derv * ent_grad\n",
    "    \n",
    "    output_derv = softmax_derv(output, probs)\n",
    "    output_grad = [np.matmul(output_derv[n], probs_grad[n]) \\\n",
    "                   for n in range(output.shape[0])]\n",
    "    \n",
    "    proc_backward(x, output_grad)\n",
    "    \n",
    "    return loss, eval_accuracy(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(batch_size=0):\n",
    "    if batch_size == 0: batch_size = train_count\n",
    "    batch_count = int(train_count / batch_size)\n",
    "    test_X, test_Y = get_test_data()\n",
    "        \n",
    "    init_parameter()\n",
    "    \n",
    "    if random_fix: np.random.seed(1945)\n",
    "        \n",
    "    for epoch in range(epoch_count):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        for n in range(batch_count):\n",
    "            train_X, train_Y = get_train_data(batch_size, n)\n",
    "            cost, acc = train_step(train_X, train_Y)\n",
    "            costs.append(cost)\n",
    "            accs.append(acc)\n",
    "            \n",
    "        if (epoch+1) % report_period == 0:\n",
    "            acc = test(test_X, test_Y)\n",
    "            print(\"Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f}\". \\\n",
    "                  format(epoch+1, np.mean(costs), np.mean(accs), acc))\n",
    "            \n",
    "    final_acc = test(test_X, test_Y)\n",
    "    print(\"\\nFinal Test: final accuracy = {:5.3f}\".format(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 20: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 30: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 40: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 50: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 60: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 70: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 80: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 90: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 100: cost=1.098, accuracy=0.358/0.233\n",
      "\n",
      "Final Test: final accuracy = 0.233\n"
     ]
    }
   ],
   "source": [
    "train_and_test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 20: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 30: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 40: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 50: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 60: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 70: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 80: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 90: cost=1.099, accuracy=0.358/0.233\n",
      "Epoch 100: cost=1.099, accuracy=0.358/0.233\n",
      "\n",
      "Final Test: final accuracy = 0.233\n"
     ]
    }
   ],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 20: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 30: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 40: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 50: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 60: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 70: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 80: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 90: cost=1.098, accuracy=0.358/0.233\n",
      "Epoch 100: cost=1.098, accuracy=0.358/0.233\n",
      "\n",
      "Final Test: final accuracy = 0.233\n"
     ]
    }
   ],
   "source": [
    "train_and_test(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
