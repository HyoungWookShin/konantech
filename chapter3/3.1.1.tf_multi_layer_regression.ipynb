{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "rand_std = 0.030\n",
    "learning_rate = 0.001\n",
    "epoch_count = 100\n",
    "report_period = 10\n",
    "random_fix = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "data = iris_dataset.data\n",
    "target = iris_dataset.target\n",
    "target_names = iris_dataset.target_names\n",
    "\n",
    "#print(\"dimension: data{}, target{}, target_names{}\".\n",
    "#    format(data.shape, target.shape, target_names.shape))\n",
    "#print(target_names)\n",
    "#print(data[:5])\n",
    "#print(target[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_fix: np.random.seed(1234)\n",
    "\n",
    "data_count = len(data)\n",
    "train_count = int(data_count * train_ratio)\n",
    "test_count = data_count - train_count\n",
    "    \n",
    "indices = np.arange(data_count)\n",
    "np.random.shuffle(indices)\n",
    "    \n",
    "train_data = data[indices[0:train_count]]\n",
    "train_target = target[indices[0:train_count]]\n",
    "    \n",
    "test_data = data[indices[train_count:data_count]]\n",
    "test_target = target[indices[train_count:data_count]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, output_dim = 3, 1\n",
    "\n",
    "def get_test_data():\n",
    "    test_X = test_data[:, 0:3]\n",
    "    test_Y = test_data[:, 3:4]\n",
    "\n",
    "    return test_X, test_Y\n",
    "\n",
    "def get_train_data(batch_size, nth):\n",
    "    global indices\n",
    "    \n",
    "    if nth == 0:\n",
    "        indices = np.arange(train_count)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    from_idx = nth * batch_size\n",
    "    to_idx = (nth + 1) * batch_size\n",
    "    \n",
    "    train_X = train_data[indices[from_idx:to_idx], 0:3]\n",
    "    train_Y = train_data[indices[from_idx:to_idx], 3:4]   \n",
    "    \n",
    "    return train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rand_normal(in_dim, out_dim):\n",
    "    if not random_fix:\n",
    "        init = tf.random_normal([in_dim, out_dim], stddev=rand_std)\n",
    "    else:\n",
    "        init_64 = np.random.normal(0, rand_std, [in_dim, out_dim])\n",
    "        init = init_64.astype('float32')\n",
    "\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 10\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, input_dim])\n",
    "y = tf.placeholder(\"float\", [None, output_dim])\n",
    "\n",
    "if random_fix: np.random.seed(9876)\n",
    "\n",
    "w_hid = tf.Variable(init_rand_normal(input_dim, hidden_dim))\n",
    "b_hid = tf.Variable(tf.zeros([hidden_dim]))\n",
    "\n",
    "w_out = tf.Variable(init_rand_normal(hidden_dim, output_dim))\n",
    "b_out = tf.Variable(tf.zeros([output_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.nn.relu(tf.matmul(x, w_hid) + b_hid)\n",
    "output = tf.matmul(hidden, w_out) + b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.pow(output-y, 2))\n",
    "accuracy = 1 - tf.reduce_mean(tf.abs(output-y) / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(batch_size=0):\n",
    "    if batch_size == 0: batch_size = train_count\n",
    "    batch_count = int(train_count / batch_size)\n",
    "    \n",
    "    test_X, test_Y = get_test_data()\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    if random_fix: np.random.seed(1945)\n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        for n in range(batch_count):\n",
    "            train_X, train_Y = get_train_data(batch_size, n)\n",
    "            _, cost, acc = sess.run([train_op, loss, accuracy], \\\n",
    "                                    feed_dict={x:train_X, y:train_Y})\n",
    "            costs.append(cost)\n",
    "            accs.append(acc)\n",
    "            \n",
    "        if (epoch+1) % report_period == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={x:test_X, y:test_Y})\n",
    "            print(\"Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f}\". \\\n",
    "                  format(epoch+1, np.mean(costs), np.mean(accs), acc))\n",
    "            \n",
    "    final_acc = sess.run(accuracy, feed_dict={x:test_X, y:test_Y})\n",
    "    print(\"\\nFinal Test: final accuracy = {:5.3f}\".format(final_acc))\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=0.548, accuracy=0.070/-0.261\n",
      "Epoch 20: cost=0.265, accuracy=-0.221/-0.648\n",
      "Epoch 30: cost=0.229, accuracy=-0.130/-0.556\n",
      "Epoch 40: cost=0.196, accuracy=-0.040/-0.436\n",
      "Epoch 50: cost=0.165, accuracy=0.074/-0.317\n",
      "Epoch 60: cost=0.137, accuracy=0.179/-0.184\n",
      "Epoch 70: cost=0.112, accuracy=0.277/-0.049\n",
      "Epoch 80: cost=0.092, accuracy=0.388/0.071\n",
      "Epoch 90: cost=0.077, accuracy=0.468/0.194\n",
      "Epoch 100: cost=0.066, accuracy=0.555/0.294\n",
      "\n",
      "Final Test: final accuracy = 0.294\n"
     ]
    }
   ],
   "source": [
    "train_and_test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=1.866, accuracy=0.065/0.088\n",
      "Epoch 20: cost=1.779, accuracy=0.130/0.170\n",
      "Epoch 30: cost=1.684, accuracy=0.201/0.259\n",
      "Epoch 40: cost=1.580, accuracy=0.265/0.283\n",
      "Epoch 50: cost=1.462, accuracy=0.335/0.310\n",
      "Epoch 60: cost=1.329, accuracy=0.359/0.294\n",
      "Epoch 70: cost=1.183, accuracy=0.341/0.237\n",
      "Epoch 80: cost=1.028, accuracy=0.305/0.158\n",
      "Epoch 90: cost=0.871, accuracy=0.249/0.066\n",
      "Epoch 100: cost=0.723, accuracy=0.181/-0.042\n",
      "\n",
      "Final Test: final accuracy = -0.042\n"
     ]
    }
   ],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost=0.074, accuracy=0.521/0.291\n",
      "Epoch 20: cost=0.049, accuracy=0.783/0.668\n",
      "Epoch 30: cost=0.048, accuracy=0.795/0.704\n",
      "Epoch 40: cost=0.046, accuracy=0.797/0.712\n",
      "Epoch 50: cost=0.045, accuracy=0.802/0.692\n",
      "Epoch 60: cost=0.044, accuracy=0.808/0.692\n",
      "Epoch 70: cost=0.044, accuracy=0.799/0.702\n",
      "Epoch 80: cost=0.043, accuracy=0.809/0.673\n",
      "Epoch 90: cost=0.043, accuracy=0.804/0.707\n",
      "Epoch 100: cost=0.042, accuracy=0.799/0.702\n",
      "\n",
      "Final Test: final accuracy = 0.702\n"
     ]
    }
   ],
   "source": [
    "train_and_test(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
