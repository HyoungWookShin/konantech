{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from /data1/dhyoon/tensor_work/book_main/model/multiple_layer_model.ipynb\n"
     ]
    }
   ],
   "source": [
    "import notebook_loader\n",
    "from model import multiple_layer_model as mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.random_fix = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model iris-regression-test-hid-1 train report:\n",
      "    Epoch 10: cost=0.548, accuracy=0.070/-0.261 (1/1 secs)\n",
      "    Epoch 20: cost=0.264, accuracy=-0.211/-0.654 (0/1 secs)\n",
      "    Epoch 30: cost=0.229, accuracy=-0.134/-0.556 (0/1 secs)\n",
      "    Epoch 40: cost=0.196, accuracy=-0.028/-0.441 (0/1 secs)\n",
      "    Epoch 50: cost=0.165, accuracy=0.067/-0.314 (1/2 secs)\n",
      "    Epoch 60: cost=0.137, accuracy=0.169/-0.178 (0/2 secs)\n",
      "    Epoch 70: cost=0.112, accuracy=0.280/-0.052 (0/2 secs)\n",
      "    Epoch 80: cost=0.092, accuracy=0.379/0.078 (0/2 secs)\n",
      "    Epoch 90: cost=0.077, accuracy=0.472/0.194 (1/3 secs)\n",
      "    Epoch 100: cost=0.066, accuracy=0.547/0.297 (0/3 secs)\n",
      "\n",
      "Model notf-iris-regression-hid-1 train report:\n",
      "    Epoch 10: cost=0.548, accuracy=-0.228/-0.642 (0/0 secs)\n",
      "    Epoch 20: cost=0.264, accuracy=0.169/-0.162 (0/0 secs)\n",
      "    Epoch 30: cost=0.229, accuracy=0.175/-0.090 (0/0 secs)\n",
      "    Epoch 40: cost=0.196, accuracy=0.266/-0.014 (0/0 secs)\n",
      "    Epoch 50: cost=0.165, accuracy=0.317/0.059 (0/0 secs)\n",
      "    Epoch 60: cost=0.137, accuracy=0.371/0.135 (0/0 secs)\n",
      "    Epoch 70: cost=0.112, accuracy=0.454/0.207 (0/0 secs)\n",
      "    Epoch 80: cost=0.092, accuracy=0.512/0.279 (0/0 secs)\n",
      "    Epoch 90: cost=0.077, accuracy=0.547/0.345 (0/0 secs)\n",
      "    Epoch 100: cost=0.066, accuracy=0.594/0.401 (0/0 secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id1 = mlp.IrisDataset(\"regression\")\n",
    "\n",
    "m1 = mlp.MultiLayerPerceptronModel(\"iris-regression-test-hid-1\", id1, [10])\n",
    "m1.train(epoch_count=100)\n",
    "\n",
    "m2 = mlp.NoTFMLPModel(\"notf-iris-regression-hid-1\", id1, [10])\n",
    "m2.train(epoch_count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'babo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5d90c90adac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbabo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'babo' is not defined"
     ]
    }
   ],
   "source": [
    "print(babo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDataset(mlp.Dataset):\n",
    "    pass\n",
    "\n",
    "def unpack_map(line):\n",
    "    quiz = np.zeros([81], dtype=np.int8)\n",
    "    solution = np.zeros([81], dtype=np.int8)\n",
    "    for n in range(81):\n",
    "        quiz[n] = int(line[n])\n",
    "        solution[n] = int(line[n+82])\n",
    "    return quiz, solution\n",
    "\n",
    "def sudoku_init(self, max_count=0, train_ratio=0.80, valid_ratio=0.05):\n",
    "    if mlp.random_fix: np.random.seed(3456)\n",
    "    \n",
    "    mlp.Dataset.__init__(self, \"sudoku\")\n",
    "    \n",
    "    quizzes, solutions = [], []\n",
    "\n",
    "    for line in open(\"./data/sudoku.csv\"):\n",
    "        if line[0] == 'q': continue\n",
    "        quiz, solution = unpack_map(line)\n",
    "        \n",
    "        \n",
    "        open_cnt = np.random.randint(61-np.count_nonzero(quiz))\n",
    "        \n",
    "        for n in range(open_cnt):\n",
    "            pos = np.random.randint(81)\n",
    "            quiz[pos] = solution[pos]\n",
    "            \n",
    "        #quiz = solution\n",
    "        #for n in range(5):\n",
    "        #    pos = np.random.randint(81)\n",
    "        #    quiz[pos] = 0\n",
    "        #quizzes.append(solution)\n",
    "        #solutions.append(solution)\n",
    "        \n",
    "        #open_cnt = int((81-np.count_nonzero(quiz)) / 10)\n",
    "        #for n in range(5):\n",
    "        #    quizzes.append(quiz)\n",
    "        #    solutions.append(solution)\n",
    "        #    quiz = fill_hints(quiz, solution, open_cnt)\n",
    "            \n",
    "        quizzes.append(quiz)\n",
    "        solutions.append(solution)\n",
    "        \n",
    "        if max_count > 0 and len(quizzes) >= max_count: break\n",
    "\n",
    "    ones = np.ones([81]).astype(int)\n",
    "    solution_idxes = solutions - ones\n",
    "    xs = np.asarray(quizzes)\n",
    "    ys = np.eye(9)[solution_idxes].reshape(-1, 81*9)\n",
    "\n",
    "    self.input_dim = 81\n",
    "    self.output_dim = 81 * 9\n",
    "    #self.output_dim = 81*9\n",
    "\n",
    "    data_count = len(xs)\n",
    "    train_count = int(data_count * train_ratio)\n",
    "    valid_count = int(data_count * valid_ratio)\n",
    "    test_count = data_count - train_count - valid_count\n",
    "    print(\"sudoku data was prepared {}+{}+{}={} items\".format(train_count, valid_count, test_count, data_count))\n",
    "\n",
    "    test_start_idx = train_count + valid_count\n",
    "\n",
    "    indices = np.arange(data_count)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    self.train_xs = xs[indices[0:train_count]]\n",
    "    self.train_ys = ys[indices[0:train_count]]\n",
    "    self.validate_xs = xs[indices[train_count:test_start_idx]]\n",
    "    self.validate_ys = ys[indices[train_count:test_start_idx]]\n",
    "    self.test_xs = xs[indices[test_start_idx:]]\n",
    "    self.test_ys = ys[indices[test_start_idx:]]\n",
    "\n",
    "    self.train_count = train_count\n",
    "    \n",
    "SudokuDataset.__init__ = sudoku_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuCnnModel(mlp.MultiLayerPerceptronModel):\n",
    "    pass\n",
    "\n",
    "def sudoku_init(self, name, dataset, hidden_dims, learning_rate=0.01):\n",
    "    mlp.MultiLayerPerceptronModel.__init__(self, name, dataset, hidden_dims, learning_rate)\n",
    "\n",
    "SudokuCnnModel.__init__ = sudoku_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sudoku_train(self, epoch_count=10, batch_size=10):\n",
    "    if batch_size == 0:\n",
    "        batch_size = self.dataset.train_count\n",
    "        \n",
    "    batch_count = int(self.dataset.train_count / batch_size)\n",
    "    report_period = epoch_count / 10\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    if mlp.random_fix: np.random.seed(1945)\n",
    "    \n",
    "    time1 = time2 = int(time.time())\n",
    "    \n",
    "    print(\"Model {} train report:\".format(self.name))\n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        costs, total_accs, blank_accs, max_accs =  [], [], [], []\n",
    "        \n",
    "        for n in range(batch_count):\n",
    "            train_X, train_Y = self.dataset.get_train_data(batch_size, n)\n",
    "            _, cost, total_acc, blank_acc, max_acc = \\\n",
    "                sess.run([self.train_op, self.loss, self.total_acc, self.blank_acc, self.max_acc], \\\n",
    "                         feed_dict={self.x:train_X, self.y:train_Y})\n",
    "            costs.append(cost)\n",
    "            total_accs.append(total_acc)\n",
    "            blank_accs.append(blank_acc)\n",
    "            max_accs.append(max_acc)\n",
    "        \n",
    "        if (epoch+1) % report_period == 0:\n",
    "            validate_X, validate_Y = self.dataset.get_test_data(True, 30)\n",
    "            total_acc, blank_acc, max_acc = sess.run([self.total_acc, self.blank_acc, self.max_acc], \\\n",
    "                                                          feed_dict={self.x:validate_X, self.y:validate_Y})\n",
    "\n",
    "            time3 = int(time.time())\n",
    "            print(\"    Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f}/{:5.3f}({:5.3f}/{:5.3f}/{:5.3f}) ({}/{} secs)\". \\\n",
    "                  format(epoch+1, np.mean(costs), np.mean(total_accs), np.mean(blank_accs), np.mean(max_accs), total_acc, blank_acc, max_acc, time3-time2, time3-time1))\n",
    "            time2 = time3\n",
    "\n",
    "    \"\"\"\n",
    "    validate_X, validate_Y = self.dataset.get_test_data(True, 2)\n",
    "    estimate, answer, correct, total_acc, non_blank_mask, non_blank_correct, non_blank_acc, \\\n",
    "    blank_mask, blank_correct, blank_acc, probs, max_probs, blank_probs, max_prob_pos, \\\n",
    "    max_prob_mask, max_prob_est, max_prob_ans, max_correct, max_acc = \\\n",
    "        sess.run([self.estimate, self.answer, self.correct, self.total_acc, \\\n",
    "                  self.non_blank_mask, self.non_blank_correct, self.non_blank_acc, \\\n",
    "                  self.blank_mask, self.blank_correct, self.blank_acc, \\\n",
    "                  self.probs, self.max_probs, self.blank_probs, self.max_prob_pos, self.max_prob_mask, \\\n",
    "                  self.max_prob_est, self.max_prob_ans, self.max_correct, self.max_acc], \\\n",
    "                                                    feed_dict={self.x:validate_X, self.y:validate_Y})\n",
    "    print(\"estimate\", np.reshape(estimate, [-1, 9]))\n",
    "    print(\"answer\", np.reshape(answer, [-1, 9]))\n",
    "    print(\"correct\", np.reshape(correct, [-1, 9]))\n",
    "    print(\"total_acc\", total_acc)\n",
    "    print(\"x\", np.reshape(validate_X, [-1, 9]))\n",
    "    print(\"non_blank_mask\", np.reshape(non_blank_mask, [-1, 9]))\n",
    "    print(\"non_blank_correct\", np.reshape(non_blank_correct, [-1, 9]))\n",
    "    print(\"non_blank_acc\", non_blank_acc)\n",
    "    print(\"blank_mask\", np.reshape(blank_mask, [-1, 9]))\n",
    "    print(\"blank_correct\", np.reshape(blank_correct, [-1, 9]))\n",
    "    print(\"blank_acc\", blank_acc)\n",
    "    print(\"probs\", np.reshape(probs, [-1, 9]))\n",
    "    print(\"max_probs\", np.reshape(max_probs, [-1, 9]))\n",
    "    print(\"blank_probs\", np.reshape(blank_probs, [-1, 9]))\n",
    "    print(\"max_prob_pos\", max_prob_pos)\n",
    "    print(\"max_prob_mask\", np.reshape(max_prob_mask, [-1, 9]))\n",
    "    print(\"max_prob_est\", max_prob_est)\n",
    "    print(\"max_prob_ans\", max_prob_ans)\n",
    "    print(\"max_correct\", max_correct)\n",
    "    print(\"max_acc\", max_acc)\n",
    "    \"\"\"\n",
    "    \n",
    "    path = \"params/{}.ckpt\".format(self.name)\n",
    "    self.saver.save(sess, path)\n",
    "    sess.close()\n",
    "\n",
    "SudokuCnnModel.train = sudoku_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sudoku_build_loss_accuracy(self):\n",
    "    \n",
    "    labels = tf.cast(tf.reshape(self.y, [-1, 81, 9]), \"float\")\n",
    "    logits = tf.reshape(self.output, [-1, 81, 9])\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    loss = tf.reduce_mean(entropy)\n",
    "    \n",
    "    estimate = tf.argmax(logits, 2)\n",
    "    answer = tf.argmax(labels, 2)\n",
    "    correct = tf.cast(tf.equal(estimate, answer), \"float\")\n",
    "    total_acc = tf.reduce_mean(correct)\n",
    "    \n",
    "    non_blank_mask = tf.cast(tf.sign(self.x), \"float\")\n",
    "    non_blank_correct = non_blank_mask * correct\n",
    "    non_blank_acc = tf.reduce_sum(non_blank_correct) / tf.reduce_sum(non_blank_mask)\n",
    "\n",
    "    blank_mask = 1 - non_blank_mask\n",
    "    blank_correct = blank_mask * correct\n",
    "    blank_acc = tf.reduce_sum(blank_correct) / tf.reduce_sum(blank_mask)\n",
    "\n",
    "    #self.estimate = estimate\n",
    "    #self.answer = answer\n",
    "    #self.correct = correct\n",
    "\n",
    "    #self.non_blank_mask = non_blank_mask\n",
    "    #self.non_blank_correct = non_blank_correct\n",
    "\n",
    "    #self.blank_mask = blank_mask\n",
    "    #self.blank_correct = blank_correct\n",
    "\n",
    "    probs = tf.nn.softmax(logits)\n",
    "    max_probs = tf.reduce_max(probs, axis=2)\n",
    "    blank_probs = blank_mask * max_probs\n",
    "    max_prob_pos = tf.argmax(blank_probs, 1)\n",
    "    max_prob_mask = tf.one_hot(max_prob_pos, 81)\n",
    "    max_prob_est = tf.reduce_sum(tf.cast(estimate, \"float\")*max_prob_mask, 1)\n",
    "    max_prob_ans = tf.reduce_sum(tf.cast(answer, \"float\")*max_prob_mask, 1)\n",
    "    max_correct = tf.cast(tf.equal(max_prob_est, max_prob_ans), \"float\")\n",
    "    max_acc = tf.reduce_mean(max_correct)\n",
    "\n",
    "    self.loss = loss\n",
    "    #self.probs = probs\n",
    "    #self.max_probs = max_probs\n",
    "    #self.blank_probs = blank_probs\n",
    "    #self.max_prob_pos = max_prob_pos\n",
    "    #self.max_prob_mask = max_prob_mask\n",
    "    #self.max_prob_est = max_prob_est\n",
    "    #self.max_prob_ans = max_prob_ans\n",
    "    #self.max_correct = max_correct\n",
    "    self.total_acc = total_acc\n",
    "    self.blank_acc = blank_acc\n",
    "    self.max_acc = max_acc\n",
    "\n",
    "SudokuCnnModel.build_loss_accuracy = sudoku_build_loss_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1 = SudokuDataset(max_count=1000)\n",
    "\n",
    "sm1 = SudokuCnnModel(\"sudoku-mlp-1\", sd1, [256])\n",
    "sm1.train(epoch_count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2 = SudokuDataset(max_count=10000)\n",
    "\n",
    "sm2 = SudokuCnnModel(\"sudoku-mlp-2\", sd2, [256])\n",
    "sm2.train(epoch_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm3 = SudokuCnnModel(\"sudoku-mlp-3\", sd1, [256])\n",
    "sm3.train(epoch_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm4 = SudokuCnnModel(\"sudoku-mlp-4\", sd2, [256])\n",
    "sm4.train(epoch_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
